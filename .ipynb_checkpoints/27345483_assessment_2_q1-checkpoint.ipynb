{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Ridge Regression\n",
    "\n",
    "## ii\n",
    "Using R (with no use of special libraries), implement SGD and BGD algorithms that\n",
    "you derived in Step I. The implementation is straightforward as you are allowed to\n",
    "use the code examples from Activity 1 in Module 2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "Loading required package: reshape2\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "require(ggplot2)\n",
    "require(reshape2)\n",
    "\n",
    "\n",
    "# import datasets\n",
    "testData <- read.csv(\"./Task2A_test.csv\")\n",
    "testLabel <- testData[, 'y']\n",
    "testData <- testData[, 1:4]\n",
    "trainData <- read.csv(\"./Task2A_train.csv \")\n",
    "trainLabel <- trainData[, 'y']\n",
    "trainData <- trainData[, 1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tackle Stochastic Descent first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stochasticDescent <- function(trainData, trainLabel, testData = NULL, testLabel = NULL, eta = 0.00000000001, iterMax = 10000, lambda = 0.2, epsilon = 0.1, basis = 1, seed = 1234) {\n",
    "\n",
    "    # reproducibility\n",
    "    if (!is.null(seed)) {\n",
    "        set.seed(seed);\n",
    "    };\n",
    "\n",
    "    # this function uses stochastic descent to find the optimal parameter weights for regression function.\n",
    "\n",
    "    ## parameterisation ##\n",
    "\n",
    "    # training data length\n",
    "    trainLen <- nrow(trainData);\n",
    "    # learning rate\n",
    "    eta_ <- eta;\n",
    "    # max number if iterations\n",
    "    iterMax_ <- iterMax;\n",
    "    # lambda value\n",
    "    lambda_ <- lambda;\n",
    "    # rmse terminiation condition\n",
    "    epsilon_ <- epsilon;\n",
    "\n",
    "    ## containers ##\n",
    "\n",
    "    # develop basis function and container\n",
    "    phi_ <- as.matrix(cbind('x0' = basis, trainData));\n",
    "    # container for coefficients\n",
    "    w_ <- matrix(, nrow = iterMax_, ncol = ncol(phi_));\n",
    "    # container for errors\n",
    "    err_ <- data.frame('iteration' = 1:iterMax_);\n",
    "\n",
    "    ## utility functions ##\n",
    "\n",
    "    f_prediction <- function(phi, w) {\n",
    "        # basis function * params.\n",
    "        return(phi %*% w);\n",
    "    }\n",
    "\n",
    "    f_error <- function(phi, w, label) {\n",
    "        # rmse\n",
    "        return(sqrt(sum((((label - f_prediction(phi = phi, w = w)) ^ 2) / 2))));\n",
    "    }\n",
    "\n",
    "\n",
    "    ## initialisation ##\n",
    "\n",
    "    # initialise iterations\n",
    "    iter_ <- 1;\n",
    "    # guess initial coefficients\n",
    "    w_[iter_,] <- rnorm(ncol(phi_));\n",
    "    # initialise termination flag\n",
    "    term_ <- FALSE;\n",
    "\n",
    "    # Begin Descent\n",
    "    while (!term_) {\n",
    "\n",
    "        # check termination criteron\n",
    "        term_ <- iter_ >= iterMax_ | epsilon_ > f_error(phi = phi_, w = w_[iter_,], label = trainLabel);\n",
    "\n",
    "        # randomise data\n",
    "        trainIndex_ <- sample(1:trainLen, trainLen, replace = FALSE);\n",
    "\n",
    "        # rearrange the basis function and training labels (do this locally).\n",
    "        phi_ <- phi_[trainIndex_,];\n",
    "        trLabels_ <- trainLabel[trainIndex_];\n",
    "\n",
    "        # visit data point\n",
    "        for (n in 1:trainLen) {\n",
    "\n",
    "            # calculate error in iter, it should terminiate correctly.\n",
    "            err_[iter_, 'train'] <- f_error(phi = as.matrix(cbind(1, trainData)), w = w_[iter_,], trainLabel);\n",
    "            if (!is.null(testData)) {\n",
    "                err_[iter_, 'test'] <- f_error(phi = as.matrix(cbind(1, testData)), w = w_[iter_,], testLabel);\n",
    "            }\n",
    "\n",
    "            # check for termination criterea.\n",
    "            if (iter_ >= iterMax_) {\n",
    "                term_ <- TRUE;\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            # make a prediction with teh current coefficients for the datapoint.\n",
    "            wPhi_ <- f_prediction(phi = phi_[n,], w = w_[iter_,]);\n",
    "\n",
    "            # for each coefficient, use the loss function to update the coefficients.\n",
    "            for (c in 1:ncol(w_)) {\n",
    "\n",
    "                w_[iter_ + 1, c] <- w_[iter_, c] + eta_ * sum((trLabels_[n] - wPhi_) * phi_[n, c] + (lambda_ * w_[iter_, c]));\n",
    "                # L2\n",
    "            }\n",
    "            # increment iterator.\n",
    "            iter_ = iter_ + 1;\n",
    "        }\n",
    "    }\n",
    "    # return objects as list.\n",
    "    return(list('coefficients' = w_[iter_ - 1,], 'errors' = err_));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Descent next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchDescent <- function(trainData, trainLabel, testData = NULL, testLabel = NULL, eta = 0.1, iterMax = 1000, lambda = 0.2, epsilon = 0.000000000001, basis = 1, seed = 1234) {\n",
    "\n",
    "    # reproducibility\n",
    "    if (!is.null(seed)) {\n",
    "        set.seed(seed);\n",
    "    };\n",
    "\n",
    "    # this function uses batch descent to find the optimal parameter weights for regression function.\n",
    "\n",
    "    ## parameterisation ##\n",
    "\n",
    "    # training data length\n",
    "    trainLen <- nrow(trainData);\n",
    "    # learning rate\n",
    "    eta_ <- eta;\n",
    "    # max number if iterations\n",
    "    iterMax_ <- iterMax;\n",
    "    # lambda value\n",
    "    lambda_ <- lambda;\n",
    "    # rmse terminiation condition\n",
    "    epsilon_ <- epsilon;\n",
    "\n",
    "    ## containers ##\n",
    "\n",
    "    # develop basis function and container\n",
    "    phi_ <- as.matrix(cbind('x0' = basis, trainData));\n",
    "    # container for coefficients\n",
    "    w_ <- matrix(, nrow = iterMax_, ncol = ncol(phi_));\n",
    "    # container for errors\n",
    "    err_ <- data.frame('iteration' = 1:iterMax_);\n",
    "\n",
    "    ## utility functions ##\n",
    "\n",
    "    f_prediction <- function(phi, w) {\n",
    "        # basis function * params.\n",
    "        return(phi %*% w);\n",
    "    }\n",
    "\n",
    "    f_error <- function(phi, w, label) {\n",
    "        # rmse\n",
    "        return(sqrt(sum((((label - f_prediction(phi = phi, w = w)) ^ 2) / 2))));\n",
    "    }\n",
    "\n",
    "    ## initialisation ##\n",
    "\n",
    "    # initialise iterations\n",
    "    iter_ <- 1;\n",
    "    # guess initial coefficients\n",
    "    w_[iter_,] <- rnorm(ncol(phi_));\n",
    "    # initialise termination flag\n",
    "    term_ <- FALSE;\n",
    "\n",
    "    # Begin Descent\n",
    "    while (!term_) {\n",
    "\n",
    "        # set terminiation critereon.\n",
    "        term_ <- iter_ >= iterMax_ | epsilon_ > f_error(phi = phi_, w = w_[iter_,], trainLabel);\n",
    "\n",
    "        # make prediction from the current coefficients;\n",
    "        wPhi_ <- f_prediction(phi = phi_, w = w_[iter_,]);\n",
    "\n",
    "        # initialise line search eta for decay\n",
    "        etaPrime_ <- eta_;\n",
    "\n",
    "        # begin line search\n",
    "        while (etaPrime_ > epsilon_) {\n",
    "\n",
    "            # check termination criteria\n",
    "            if (iter_ >= iterMax | epsilon_ > f_error(phi = phi_, w = w_[iter_, ], trainLabel)) {\n",
    "                term_ <- TRUE;\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            # update coeffs for each column\n",
    "            for (c in 1:ncol(w_)) {\n",
    "                w_[iter_ + 1, c] <- w_[iter_, c] + etaPrime_ * sum((trainLabel - wPhi_) * phi_[, c] + (lambda_ * w_[iter_, c]));\n",
    "            }\n",
    "            \n",
    "            # get the errors for comparison\n",
    "            eIter <- f_error(phi = phi_, w = w_[iter_,], trainLabel);\n",
    "            eIterPlus1 <- f_error(phi = phi_, w = w_[iter_ + 1,], trainLabel);\n",
    "\n",
    "            # break if no improvement\n",
    "            if (eIter > eIterPlus1) {\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            # decay eta \n",
    "            etaPrime_ = etaPrime_ / 2;\n",
    "        }\n",
    "\n",
    "        # record error\n",
    "        err_[iter_, 'train'] <- f_error(phi = phi_, w = w_[iter_,], trainLabel);\n",
    "        if (!is.null(testData)) {\n",
    "            err_[iter_, 'test'] <- f_error(phi = as.matrix(cbind(1, testData)), w = w_[iter_,], testLabel);\n",
    "        }\n",
    "\n",
    "        # record eta usage\n",
    "        err_[iter_, 'eta'] <- etaPrime_;\n",
    "\n",
    "        iter_ = iter_ + 1;\n",
    "\n",
    "    }\n",
    "\n",
    "    return(list('coeffs' = w_[iter_ - 1,], 'errors' = err_));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the functions with 20 * 930 updates for SGD and 20 for BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run sgd\n",
    "sgd_ <- stochasticDescent(trainData, trainLabel, iterMax = 20 * nrow(trainData));\n",
    "\n",
    "sgdErr <- sgd_$errors\n",
    "\n",
    "# run bgd\n",
    "bgd_ <- batchDescent(trainData, trainLabel, iterMax = 20);\n",
    "\n",
    "bgdErr <- bgd_$errors\n",
    "\n",
    "\n",
    "# record errors\n",
    "errsTot <- data.frame('iter' = 1:nrow(sgdErr))\n",
    "# merge sgd\n",
    "errsTot <- merge(errsTot, sgdErr, by.x = 'iter', by.y = 'iteration')\n",
    "# rename sgd training error\n",
    "names(errsTot)[names(errsTot) == 'train'] <- \"SGD Training Error\";\n",
    "\n",
    "# adjust key for bgd error for merge\n",
    "bgdErr[, 'iterKey'] <- seq(1, 18600, 930)\n",
    "\n",
    "errsTot <- merge(errsTot, bgdErr, by.x = 'iter', by.y = 'iterKey', all.x = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": Removed 18580 rows containing missing values (geom_point)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rename bgd training error\n",
    "names(errsTot)[names(errsTot) == 'train'] <- \"BGD Training Error\";\n",
    "\n",
    "# clean up dataframe\n",
    "errsTot <- subset(errsTot, select = c(\"iter\", \"SGD Training Error\", \"BGD Training Error\"))\n",
    "\n",
    "errMelt <- melt(errsTot, id = 'iter')\n",
    "\n",
    "ggplot(errMelt, aes(x = iter, y = value, colour = variable)) + geom_point() + ggtitle(\"BGD vs SGD Errors\") + ylab(\"Error\") + xlab(\"Visited Data Points\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
